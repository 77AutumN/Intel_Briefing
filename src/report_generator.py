#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Report Generator - æŠ¥å‘Šç”Ÿæˆæ¨¡å—
è´Ÿè´£å°†æƒ…æŠ¥æ•°æ®è½¬æ¢ä¸º Markdown æŠ¥å‘Š
"""

import time
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

# Import from centralized config
try:
    from config import GEMINI_RATE_LIMIT_DELAY
except ImportError:
    try:
        from src.config import GEMINI_RATE_LIMIT_DELAY
    except ImportError:
        GEMINI_RATE_LIMIT_DELAY = 1.5

# --- Gemini Translator ---
try:
    from utils.gemini_translator import translate_to_chinese, summarize_blog_article, generate_executive_summary
    GEMINI_AVAILABLE = True
except ImportError:
    try:
        from src.utils.gemini_translator import translate_to_chinese, summarize_blog_article, generate_executive_summary
        GEMINI_AVAILABLE = True
    except ImportError:
        GEMINI_AVAILABLE = False

# --- Jina Reader (Full Content Fetcher) ---
try:
    from utils.jina_reader import fetch_full_content
    JINA_AVAILABLE = True
except ImportError:
    JINA_AVAILABLE = False
    logger.info("Jina Reader not available, using RSS description only.")

if not GEMINI_AVAILABLE:
    logger.info("Gemini translator not available, using English summaries.")
    def translate_to_chinese(text, max_chars=100):
        return text[:max_chars] + "..." if len(text) > max_chars else text

    def summarize_blog_article(content, mode="brief"):
        return ""

    def generate_executive_summary(intel):
        return ""


def generate_report(intel: dict, date_str: str) -> str:
    """Generate magazine-style markdown report with executive summary and hidden empty sections."""

    # è®¡ç®—æ´»è·ƒæ•°æ®æº
    active_sources = []
    if intel.get("tech_trends"):
        active_sources.append("HN")
        active_sources.append("GitHub")
    if intel.get("capital_flow"):
        active_sources.append("36Kr")
        active_sources.append("WallStreetCN")
    if intel.get("community"):
        active_sources.append("V2EX")
    if intel.get("product_gems"):
        active_sources.append("PH")
    if intel.get("research"):
        active_sources.append("ArXiv")
    if intel.get("social"):
        active_sources.append("X")
    if intel.get("insights"):
        active_sources.append("Blogs")

    sources_str = ", ".join(active_sources) if active_sources else "æ— "

    lines = [
        f"# ğŸŒ å…¨çƒæƒ…æŠ¥æ—¥æŠ¥ (Global Intel Briefing)",
        f"**æ—¥æœŸ:** {date_str}",
        f"**ç”Ÿæˆæ—¶é—´:** {datetime.now().strftime('%H:%M')}",
        f"**æ•°æ®æº:** {sources_str}",
        "",
    ]

    # --- Executive Summary (AI ç”Ÿæˆ) ---
    exec_summary = generate_executive_summary(intel)
    if exec_summary:
        lines.append("## ğŸ“Œ ä»Šæ—¥è¦ç‚¹ (Executive Summary)")
        lines.append("")
        lines.append(exec_summary)
        lines.append("")

    lines.append("---")
    lines.append("")

    # --- Tech Trends (ä»…åœ¨æœ‰æ•°æ®æ—¶æ˜¾ç¤º) ---
    if intel.get("tech_trends"):
        lines.append("## ğŸ› ï¸ æŠ€æœ¯è¶‹åŠ¿ (Tech Trends)")
        lines.append("> Hacker News + GitHub Trending\n")
        for i, item in enumerate(intel["tech_trends"][:10], 1):
            title = item.get("title", "Untitled")
            url = item.get("url", "#")
            heat = item.get("heat", "")
            time_str = item.get("time", "")
            cat = item.get("category", "")

            lines.append(f"### {i}. [{title}]({url})")
            lines.append(f"ğŸ“ {cat} | ğŸ”¥ {heat} | ğŸ•’ {time_str}")
            lines.append("")

    # --- Capital Flow (ä»…åœ¨æœ‰æ•°æ®æ—¶æ˜¾ç¤º) ---
    if intel.get("capital_flow"):
        lines.append("## ğŸ’° èµ„æœ¬åŠ¨å‘ (Capital Flow)")
        lines.append("> 36Kr + åå°”è¡—è§é—»\n")
        for i, item in enumerate(intel["capital_flow"][:10], 1):
            title = item.get("title", "Untitled")
            url = item.get("url", "#")
            time_str = item.get("time", "")
            cat = item.get("category", "")

            lines.append(f"### {i}. [{title}]({url})")
            lines.append(f"ğŸ“ {cat} | ğŸ•’ {time_str}")
            lines.append("")

    # --- Research (ArXiv) (ä»…åœ¨æœ‰æ•°æ®æ—¶æ˜¾ç¤º) ---
    if intel.get("research"):
        lines.append("## ğŸ“š å­¦æœ¯å‰æ²¿ (Research)")
        lines.append("> ArXiv AI/ML Papers\n")
        for i, item in enumerate(intel["research"][:5], 1):
            title = item.get("title", "Untitled")
            url = item.get("url", "#")
            authors = item.get("authors", "")
            time_str = item.get("time", "")
            summary = item.get("summary", "").replace("\n", " ")

            brief_cn = translate_to_chinese(summary[:200], max_chars=80) if summary else ""
            if GEMINI_AVAILABLE and summary:
                time.sleep(GEMINI_RATE_LIMIT_DELAY)
            detail_cn = translate_to_chinese(summary, max_chars=2000) if summary else ""

            lines.append(f"### {i}. [{title}]({url})")
            if brief_cn:
                lines.append(f"> âš¡ {brief_cn}")

            lines.append(f"ğŸ‘¤ {authors} | ğŸ“… {time_str}")

            if detail_cn:
                lines.append("")
                lines.append(f"**è¯¦æƒ…:** {detail_cn}")

            lines.append("")

    # --- Product Gems (ä»…åœ¨æœ‰æ•°æ®æ—¶æ˜¾ç¤º) ---
    if intel.get("product_gems"):
        lines.append("## ğŸ’ äº§å“ç²¾é€‰ (Product Gems)")
        lines.append("> Product Hunt Today\n")
        for i, item in enumerate(intel["product_gems"][:8], 1):
            title = item.get("title", "Untitled")
            url = item.get("url", "#")
            heat = item.get("heat", "")
            tagline = item.get("tagline", "")
            grok_review = item.get("grok_review")

            lines.append(f"### {i}. [{title}]({url})")
            lines.append(f"> {tagline}")
            lines.append(f"ğŸ”¥ {heat}")
            lines.append("")

            if grok_review:
                lines.append(f"> **ğŸ¦… Grok èˆ†æƒ…æ ¸æŸ¥**: {grok_review}")
                lines.append("")

    # --- Social (X/Twitter) (ä»…åœ¨æœ‰æ•°æ®æ—¶æ˜¾ç¤º) ---
    if intel.get("social"):
        lines.append("## ğŸ¦ ç¤¾äº¤çƒ­è®® (Social)")
        lines.append("> X (Twitter) - AI/Tech Discussions\n")
        for item in intel["social"]:
            if item.get("type") == "markdown_report":
                lines.append(f"> æ¥æº: {item.get('source', 'X')}\n")
                lines.append(item.get("content", "*æ— å†…å®¹*"))
                lines.append("")
            else:
                title = item.get("title", "")
                url = item.get("url", "#")
                author = item.get("author", "")
                heat = item.get("heat", "")

                lines.append(f"### {author}")
                lines.append(f"> {title}")
                lines.append(f"â¤ï¸ {heat} | ğŸ”— [Link]({url})")
                lines.append("")

    # --- Community (ä»…åœ¨æœ‰æ•°æ®æ—¶æ˜¾ç¤º) ---
    if intel.get("community"):
        lines.append("## ğŸ—£ï¸ ç¤¾åŒºçƒ­ç‚¹ (Community)")
        lines.append("> V2EX çƒ­é—¨\n")
        for i, item in enumerate(intel["community"][:5], 1):
            title = item.get("title", "Untitled")
            url = item.get("url", "#")
            heat = item.get("heat", "")

            lines.append(f"### {i}. [{title}]({url})")
            lines.append(f"ğŸ’¬ {heat}")
            lines.append("")

    # --- XHS Directives (ä»…åœ¨æœ‰æ•°æ®æ—¶æ˜¾ç¤ºï¼Œä¸”è¿‡æ»¤æ‰çº¯æœç´¢é“¾æ¥) ---
    # æ³¨ï¼šXHS Radar ç›®å‰åªç”Ÿæˆæœç´¢é“¾æ¥ï¼Œä»·å€¼è¾ƒä½ï¼Œæš‚æ—¶éšè—
    # å¦‚æœåç»­å®ç°çœŸæ­£çš„å†…å®¹æŠ“å–ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Š
    # if intel.get("xhs_directives"):
    #     lines.append("## ğŸ“• å°çº¢ä¹¦é›·è¾¾ (XHS Radar)")
    #     ...

    # --- Insights (HN Top Blogs) (ä»…åœ¨æœ‰æ•°æ®æ—¶æ˜¾ç¤º) ---
    if intel.get("insights"):
        lines.append("## ğŸ’¡ æ·±åº¦æ´å¯Ÿ (Insights)")
        lines.append("> HN Top Blogs - ç²¾é€‰æŠ€æœ¯åšå®¢\n")
        for i, item in enumerate(intel["insights"][:5], 1):
            title = item.get("title", "Untitled")
            url = item.get("url", "#")
            author = item.get("author", "")
            time_str = item.get("time", "")
            rss_content = item.get("content", "").replace("\n", " ")

            # Jina full-content analysis
            source_text = ""
            if JINA_AVAILABLE and url and url.startswith("http"):
                logger.info(f"[Insights {i}] Fetching full content via Jina...")
                full_content = fetch_full_content(url)
                if full_content and len(full_content) > 200:
                    source_text = full_content
                    logger.info(f"[Insights {i}] Using Jina full content ({len(source_text)} chars)")

            if not source_text and rss_content:
                source_text = rss_content
                logger.debug(f"[Insights {i}] Fallback to RSS content ({len(source_text)} chars)")

            brief_cn = ""
            detail_cn = ""
            if source_text and GEMINI_AVAILABLE:
                brief_cn = summarize_blog_article(source_text, mode="brief")
                time.sleep(GEMINI_RATE_LIMIT_DELAY)
                detail_cn = summarize_blog_article(source_text, mode="detail")

            lines.append(f"### {i}. [{title}]({url})")
            if brief_cn:
                lines.append(f"> âš¡ {brief_cn}")

            lines.append(f"ğŸ“ {author}{' | ğŸ“… ' + time_str if time_str else ''}")

            if detail_cn:
                lines.append("")
                lines.append(f"**è¯¦æƒ…:** {detail_cn}")

            lines.append("")

    lines.append("---")
    lines.append("*æŠ¥å‘Šç”± Unified Intelligence Engine V2 è‡ªåŠ¨ç”Ÿæˆ*")

    return "\n".join(lines)


__all__ = ['generate_report']
