
import datetime
from dataclasses import dataclass
from typing import List, Tuple
import sys

# Ensure UTF-8 output
sys.stdout.reconfigure(encoding='utf-8')

@dataclass
class Lead:
    source: str
    title: str
    url: str
    summary: str
    posted_date: str
    tags: List[str]
    desperation_score: int = 0

class XHSRadar:
    """
    Scans XiaoHongShu (Web) for 'Soft-Targets'.
    Since XHS has strong anti-scraping, this sensor primarily operates in:
    1. 'Manual Protocol' mode: Generates search URLs for the user.
    2. 'Browser Protocol' mode: Provides JS snippets for the user/agent to run in console.
    """
    
    SEARCH_QUERIES = [
        # 1. ðŸŽ“ å­¦ç”Ÿå…š (Students) - Thesis & Homework
        "æ¯•è®¾æ±‚åŠ©", "pythonä»£åš", "æ•°æ®åˆ†æž æ•‘å‘½",
        
        # 2. ðŸ’¼ ç”µå•†/è¿è¥ (E-commerce) - High Value
        "ç«žå“åˆ†æž å·¥å…·", "æ‰¹é‡ é‡‡é›† å°çº¢ä¹¦", "è‡ªåŠ¨å›žå¤ è„šæœ¬", "é—²é±¼ åŠ©æ‰‹",
        
        # 3. ðŸ¢ æ‰“å·¥äºº (Office) - Excel/PDF Pain
        "Excel è‡ªåŠ¨åŒ–", "æ‰¹é‡ è½¬ PDF", "è‡ªåŠ¨å¡«è¡¨", "å‘ç¥¨ è¯†åˆ«",
        
        # 4. ðŸŽ¬ è‡ªåª’ä½“ (Creators) - Video/Image
        "è§†é¢‘ æ‰¹é‡ å‰ªè¾‘", "åŽ»æ°´å° å·¥å…·", "æ–‡æ¡ˆ ç”Ÿæˆ", "çŸ©é˜µ è¿è¥"
    ]
    
    BASE_URL = "https://www.xiaohongshu.com/search_result"
    
    # Desperation keywords for scoring (if we get data)
    DESPERATION_KEYWORDS = [
        "æ•‘å‘½", "æœ‰å¿", "æ€¥", "æˆ‘è¦ç–¯äº†", "çº¢åŒ…", "å¤ªéš¾äº†", "æ±‚æ•™"
    ]

    def fetch_leads(self, days: int = 1) -> List[Lead]:
        """
        Returns 'Manual Action' leads pointing to search results.
        And instructions on how to scrape.
        """
        print(f"ðŸ“• Preparing XHS Radar (Past {days} days)...")
        leads = []
        
        # 1. Generate Manual Link Leads
        for query in self.SEARCH_QUERIES:
            # Simple URL encoding
            encoded_query = query.replace(" ", "%20")
            url = f"{self.BASE_URL}?keyword={encoded_query}&source=web_search_result_notes"
            
            # Create a "Guide" Lead
            leads.append(Lead(
                source="å°çº¢ä¹¦-æ‰‹åŠ¨æ¨¡å¼",
                title=f"ðŸ”Ž æœç´¢æŒ‡ä»¤: {query}",
                url=url,
                summary=f"ç‚¹å‡»æŸ¥æ‰¾å…³äºŽ '{query}' çš„å¸–å­ã€‚é‡ç‚¹å…³æ³¨æ ‡ç­¾: {', '.join(self.DESPERATION_KEYWORDS)}ã€‚",
                posted_date=datetime.datetime.now().strftime("%Y-%m-%d"),
                tags=["ðŸ”æ‰‹åŠ¨æ‰§è¡Œ", "ðŸ”¥é«˜ä¿¡å·"],
                desperation_score=50 # Base score to ensure it shows up
            ))
            
        print(f"âœ… Generated {len(leads)} search directives for XHS.")
        return leads

    def get_browser_js_snippet(self) -> str:
        """
        Returns the JS code to run in Chrome Console to extract leads.
        Based on selectors: section.note-item, a.title, a.author .name, a.cover
        """
        return """
        // ðŸ› ï¸ Antigravity XHS Scraper v1.0
        (() => {
            const leads = [];
            document.querySelectorAll('section.note-item').forEach(card => {
                const titleNode = card.querySelector('a.title');
                const authorNode = card.querySelector('a.author .name');
                const linkNode = card.querySelector('a.cover') || card.querySelector('a.title');
                
                if (titleNode && linkNode) {
                    const text = titleNode.innerText;
                    // Simple Desperation Score in JS
                    let score = 0;
                    const keywords = ["æ•‘å‘½", "æœ‰å¿", "æ€¥", "çº¢åŒ…", "å´©æºƒ"];
                    if (keywords.some(k => text.includes(k))) score = 100;
                    
                    leads.push({
                        title: text,
                        url: linkNode.href,
                        author: authorNode ? authorNode.innerText : 'Unknown',
                        score: score
                    });
                }
            });
            console.log(JSON.stringify(leads, null, 2));
            return leads;
        })();
        """

if __name__ == "__main__":
    radar = XHSRadar()
    leads = radar.fetch_leads()
    print("--- Leads ---")
    for l in leads:
        print(f"{l.title} -> {l.url}")
    print("\n--- JS Snippet ---")
    print(radar.get_browser_js_snippet())
